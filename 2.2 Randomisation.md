# 2.2 Randomisation

In its simplest form, randomised trials work by splitting trial participants into two or more groups by random lot. Each group is then given a different intervention, with one of those groups typically a "control group" or "test group" that receives no intervention or the status quo.

Groups might be allocated randomly by drawing numbers out of a hat, flipping a coin or, more commonly in experimental work, using a pseudo-random number generator. It is not the experimenter that decides who gets an intervention or not, but rather chance.

Randomisation works as a control technique because it enables experimenters to hold approximately equal the sources of experimental bias, such as uncontrolled variables, between the control and treatment groups. These might even be variables of which we are ignorant.

In *Uncontrolled: The Surprising Payoff of Trial-and-Error for Business Politics and Society*, Jim Manzi gives the following example:

> [S]uppose researchers in 1950 wanted to test the efficacy of a pill designed to reduce blood pressure but did not know that about 10 percent of the human species has a specific gene variant that predisposes them to adult-onset hypertension. If the researchers selected 3,000 people, and randomly assigned 1,500 to a test group who are given the pill and 1,500 to a control group who received a placebo, then about 150 patients in each group should have the gene variant of interest (though the researchers would have no explicit information about this and wouldnâ€™t even have thought to investigate it). Therefore, when these researchers compared the change in blood pressure before and after taking the pill for the test group versus the control group, their estimate would not be biased by a much higher proportion of patients with the gene variant of interest in one group or the other

Randomisation also avoids the need for a detailed understanding of the mechanism underlying the difference in outcomes between groups. James Lind conducted what many considered to be the first clinical trial in 1747 when he gave six scurvy stricken sailors citrus juice, while denying the treatment to another six. He did not need to know that vitamin C was the mechanism, nor anything about human biology to see if it worked.

Randomisation relies on the law of large numbers, the idea that as sample size increases the sample average converges to the expected value. In the case of the experiment to reduce blood pressure, as the size of the groups increased, we would expect the proportion of people with the hypertension genetic variant to converge to around 10% in each group.

To think of what that means intuitively, if you had only ten in each group, there is a material chance the groups could have zero, one, or more people with the hypertension variant, although it would rarely be three or more. Therefore, with a small sample, the relative proportions of the variant vary markedly between groups. It is only be collecting large samples that we can expect the groups to approximately equal proportions.

In the third week of this module (week four of this unit), we will examine how to determine the required sample size.

After randomisation and application of the treatment, outcomes are then measured for each group. Within certain statistical parameters (also to be covered later in this unit), we can then take the differences between the two groups to be as a result of the different interventions we received. The treatment "caused" the differences, although as noted above, we may not understand the mechanism.

![](img/TLA_Figure_3.jpg)

## References

Haynes et al (2012) *Test, Learn, Adapt: Developing Public Policy with Randomised Controlled Trials*, Cabinet Office, https://www.gov.uk/government/publications/test-learn-adapt-developing-public-policy-with-randomised-controlled-trials

Manzi et al (2012) *Uncontrolled: The Surprising Payoff of Trial-and-Error for Business Politics and Society*, Basic Books